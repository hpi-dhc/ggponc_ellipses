{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Disable weights and biases (if installed)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "#os.environ[\"WANDB_PROJECT\"] = \"ggponc_ellipses\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Florian.Borchert/miniconda3/envs/ellipses/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from generative.dataset import EllipsesDataset\n",
    "from generative.run_experiment import get_training_args, get_trainer, get_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from hydra import compose, initialize\n",
    "\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(config_path=Path('..'), job_name='foo', version_base='1.1')\n",
    "config = compose(config_name='experiment.yaml')\n",
    "config.model_name = \"google/mt5-base\"\n",
    "config.metrics = ['exact_match', 'google_bleu']\n",
    "config.learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/Florian.Borchert/miniconda3/envs/ellipses/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = get_training_args(config, report_to=None)\n",
    "tokenizer = get_tokenizer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_ellipses = pd.read_csv('../../ggponc_annotation/notebooks/ggponc_ccnfs.tsv', sep='\\t')\n",
    "df_controls = pd.read_csv('../../ggponc_annotation/notebooks/ggponc_cnfs_controls_small.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2241, 462, 462, 2269, 447, 449)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cnfs = df_ellipses[df_ellipses.split == 'train']\n",
    "valid_cnfs = df_ellipses[df_ellipses.split == 'dev']\n",
    "test_cnfs = df_ellipses[df_ellipses.split == 'test']\n",
    "\n",
    "train_controls = df_controls[df_controls.split == 'train']\n",
    "valid_controls = df_controls[df_controls.split == 'dev']\n",
    "test_controls = df_controls[df_controls.split == 'test']\n",
    "\n",
    "len(train_cnfs), len(valid_cnfs),  len(test_cnfs), len(train_controls), len(valid_controls), len(test_controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = EllipsesDataset(pd.concat([train_cnfs.raw_sentence]), pd.concat([train_cnfs.full_resolution]), tokenizer)\n",
    "val_data = EllipsesDataset(pd.concat([valid_cnfs.raw_sentence]), pd.concat([valid_cnfs.full_resolution]), tokenizer)\n",
    "test_data = EllipsesDataset(pd.concat([test_cnfs.raw_sentence]), pd.concat([test_cnfs.full_resolution]), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = EllipsesDataset(pd.concat([train_cnfs.raw_sentence, train_controls.raw_sentence]), pd.concat([train_cnfs.full_resolution, train_controls.raw_sentence]), tokenizer)\n",
    "#val_data = EllipsesDataset(pd.concat([valid_cnfs.raw_sentence, valid_controls.raw_sentence]), pd.concat([valid_cnfs.full_resolution, valid_controls.raw_sentence]), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.num_train_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/Florian.Borchert/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/Florian.Borchert/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/Florian.Borchert/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "trainer = get_trainer(config, tokenizer, training_args, train_data, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Florian.Borchert/miniconda3/envs/ellipses/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2241\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8430\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8430' max='8430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8430/8430 1:20:05, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exact Match</th>\n",
       "      <th>Google Bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.607400</td>\n",
       "      <td>0.650882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.313107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.517200</td>\n",
       "      <td>0.224983</td>\n",
       "      <td>0.194805</td>\n",
       "      <td>0.700083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.225600</td>\n",
       "      <td>0.082987</td>\n",
       "      <td>0.569264</td>\n",
       "      <td>0.794333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.138800</td>\n",
       "      <td>0.074682</td>\n",
       "      <td>0.638528</td>\n",
       "      <td>0.864628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.129300</td>\n",
       "      <td>0.067145</td>\n",
       "      <td>0.638528</td>\n",
       "      <td>0.881820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.089500</td>\n",
       "      <td>0.062640</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.907652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.052798</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.935579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.043203</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.931939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.051200</td>\n",
       "      <td>0.044705</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.945208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.041364</td>\n",
       "      <td>0.777056</td>\n",
       "      <td>0.940287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.040044</td>\n",
       "      <td>0.790043</td>\n",
       "      <td>0.939245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>0.040498</td>\n",
       "      <td>0.794372</td>\n",
       "      <td>0.954195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.040867</td>\n",
       "      <td>0.796537</td>\n",
       "      <td>0.954624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>0.040792</td>\n",
       "      <td>0.794372</td>\n",
       "      <td>0.961728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.039819</td>\n",
       "      <td>0.807359</td>\n",
       "      <td>0.974887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.040748</td>\n",
       "      <td>0.811688</td>\n",
       "      <td>0.963877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.039203</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.977293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.041549</td>\n",
       "      <td>0.824675</td>\n",
       "      <td>0.975157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.043204</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.974638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>0.040182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.975203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.040788</td>\n",
       "      <td>0.824675</td>\n",
       "      <td>0.974956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.041207</td>\n",
       "      <td>0.822511</td>\n",
       "      <td>0.979455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.041164</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.976700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.040565</td>\n",
       "      <td>0.824675</td>\n",
       "      <td>0.974320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.041504</td>\n",
       "      <td>0.835498</td>\n",
       "      <td>0.978974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.042139</td>\n",
       "      <td>0.829004</td>\n",
       "      <td>0.979011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.041996</td>\n",
       "      <td>0.829004</td>\n",
       "      <td>0.979702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.042316</td>\n",
       "      <td>0.826840</td>\n",
       "      <td>0.978624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.041793</td>\n",
       "      <td>0.829004</td>\n",
       "      <td>0.979488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.041767</td>\n",
       "      <td>0.829004</td>\n",
       "      <td>0.979617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8430, training_loss=0.3067725738950189, metrics={'train_runtime': 4805.7988, 'train_samples_per_second': 13.989, 'train_steps_per_second': 1.754, 'total_flos': 1.58202661833216e+16, 'train_loss': 0.3067725738950189, 'epoch': 30.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 462\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.041766952723264694, 'eval_exact_match': 0.829004329004329, 'eval_google_bleu': 0.9796165711767298, 'eval_runtime': 75.9841, 'eval_samples_per_second': 6.08, 'eval_steps_per_second': 0.763, 'epoch': 30.0}\n",
      "{'test_loss': 0.046481937170028687, 'test_exact_match': 0.8181818181818182, 'test_google_bleu': 0.9743136859103755, 'test_runtime': 83.7644, 'test_samples_per_second': 5.515, 'test_steps_per_second': 0.692, 'epoch': 30.0}\n"
     ]
    }
   ],
   "source": [
    "eval_metrics = trainer.evaluate(val_data)\n",
    "print(eval_metrics)\n",
    "\n",
    "test_metrics = trainer.evaluate(test_data, metric_key_prefix='test')\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Text2TextGenerationPipeline\n",
    "from evaluation import error_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Text2TextGenerationPipeline(model=trainer.model, tokenizer=tokenizer, max_length=500, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hauptrisikofaktoren für das Auftreten eines Mundhöhlenkarzinoms sind chronischer Tabak- oder Alkoholabusus, wesentlich seltener auch andere Faktoren.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_cnfs.raw_sentence.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hauptrisikofaktoren für das Auftreten eines Mundhöhlenkarzinoms sind chronischer Tabakabusus oder Alkoholabusus, wesentlich seltener auch andere Faktoren.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_cnfs.full_resolution.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import error_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_analysis(predictions, gt_resolutions, original_sentences):\n",
    "    d = difflib.Differ()\n",
    "    res = []\n",
    "\n",
    "    for pred_gen, true, sent in zip(predictions, gt_resolutions, original_sentences):\n",
    "        entry = {'pred' : pred_gen, 'ground_truth' : true, 'original' : sent}    \n",
    "        if pred_gen == true:\n",
    "            entry['error_type'] = 'tp'\n",
    "        elif pred_gen == sent:\n",
    "            entry['error_type'] = 'fn'\n",
    "        else:\n",
    "            op_codes = difflib.SequenceMatcher(None, true, pred_gen).get_opcodes()\n",
    "            counts = Counter([o[0] for o in op_codes])\n",
    "            del counts[\"equal\"]\n",
    "            if len(counts) > 1:\n",
    "                entry['error_type'] = 'complex'\n",
    "            else:\n",
    "                entry['error_type'] = list(counts.keys())[0]\n",
    "        res.append(entry)\n",
    "    return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_errors(out, sample):\n",
    "    gen_text = [o['generated_text'] for o in out]\n",
    "    errors = error_analysis(gen_text, sample.full_resolution, sample.raw_sentence)\n",
    "    display(pd.concat([errors.error_type.value_counts(), errors.error_type.value_counts() / len(errors)], axis=1))    \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 14s, sys: 98.8 ms, total: 4min 14s\n",
      "Wall time: 4min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out_valid = pipeline(list(valid_cnfs.raw_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error_type</th>\n",
       "      <th>error_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tp</th>\n",
       "      <td>382</td>\n",
       "      <td>0.826840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delete</th>\n",
       "      <td>27</td>\n",
       "      <td>0.058442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>replace</th>\n",
       "      <td>18</td>\n",
       "      <td>0.038961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insert</th>\n",
       "      <td>16</td>\n",
       "      <td>0.034632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <td>10</td>\n",
       "      <td>0.021645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complex</th>\n",
       "      <td>9</td>\n",
       "      <td>0.019481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         error_type  error_type\n",
       "tp              382    0.826840\n",
       "delete           27    0.058442\n",
       "replace          18    0.038961\n",
       "insert           16    0.034632\n",
       "fn               10    0.021645\n",
       "complex           9    0.019481"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors_valid = calculate_errors(out_valid, valid_cnfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed = nltk.edit_distance\n",
    "def metric(p, g, o):\n",
    "    d = ed(p,g)\n",
    "    k = ed(p,o)\n",
    "    l = ed(o,g)\n",
    "    if d == 0:\n",
    "        return 1\n",
    "    return 1 - (d / (k + l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9313555280996356"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_score = errors_valid.apply(lambda r: metric(r['pred'], r['ground_truth'], r['original']), axis=1)\n",
    "my_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 42s, sys: 89.3 ms, total: 4min 42s\n",
      "Wall time: 4min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out_test = pipeline(list(test_cnfs.raw_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error_type</th>\n",
       "      <th>error_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tp</th>\n",
       "      <td>376</td>\n",
       "      <td>0.813853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delete</th>\n",
       "      <td>26</td>\n",
       "      <td>0.056277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complex</th>\n",
       "      <td>20</td>\n",
       "      <td>0.043290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insert</th>\n",
       "      <td>16</td>\n",
       "      <td>0.034632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>replace</th>\n",
       "      <td>13</td>\n",
       "      <td>0.028139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fn</th>\n",
       "      <td>11</td>\n",
       "      <td>0.023810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         error_type  error_type\n",
       "tp              376    0.813853\n",
       "delete           26    0.056277\n",
       "complex          20    0.043290\n",
       "insert           16    0.034632\n",
       "replace          13    0.028139\n",
       "fn               11    0.023810"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors_test = calculate_errors(out_test, test_cnfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9269631059037321"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_score = errors_test.apply(lambda r: metric(r['pred'], r['ground_truth'], r['original']), axis=1)\n",
    "my_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ellipses]",
   "language": "python",
   "name": "conda-env-ellipses-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f7616dd95153615ba76d82383ee4b763d06514f4c395e85d9efff1c9a575639"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_PROJECT\"] = \"xmen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM,Text2TextGenerationPipeline\n",
    "from evaluation import error_analysis, get_scores\n",
    "from dataset import load_data, get_dataloader\n",
    "from transformers_util import get_training_args, get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import hydra\n",
    "from hydra import compose, initialize\n",
    "\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(config_path=Path('..'), job_name='foo', version_base='1.1')\n",
    "config = compose(config_name='experiment.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "openai.api_key = config.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "SPLIT = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Florian.Borchert/miniconda3/envs/ellipses/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = get_training_args(config, report_to=\"none\")\n",
    "tokenizer = get_tokenizer(config)\n",
    "\n",
    "base_path = Path('..')\n",
    "train_df, val_df, test_df = load_data(base_path / config.data.cnf_tsv_path, base_path / config.data.controls_tsv_path)\n",
    "train_dataset, val_dataset, test_dataset = get_dataloader(train_df, val_df, test_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SPLIT == 'valid':\n",
    "    df = val_df\n",
    "elif SPLIT == 'test':\n",
    "    df = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(f'results_{SPLIT}')\n",
    "output_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolutions = list(df.full_resolution)\n",
    "samples = list(df.raw_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"../data/ellipses/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOP 1 generation from seq-to-seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pipeline = Text2TextGenerationPipeline(model=model, tokenizer=tokenizer, max_length=config.generation_max_length, device=0, batch_size=BATCH_SIZE)\n",
    "\n",
    "predictions = pipeline(samples)\n",
    "\n",
    "errors = error_analysis([prediction[\"generated_text\"] for prediction in predictions], resolutions, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.error_type.value_counts()# / len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.to_parquet(output_path / 'results_top1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "get_scores(errors, SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best out of TOP k predictions from seq-to-seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from evaluation import relative_edit_distance\n",
    "\n",
    "def evaluate_top_k(model, tokenizer, data, beams, generation_max_length=config.generation_max_length, debug=False):\n",
    "    pipeline = Text2TextGenerationPipeline(\n",
    "        model=model, tokenizer=tokenizer, max_length=generation_max_length, num_beams=beams, num_return_sequences=beams, device=0, batch_size=BATCH_SIZE)\n",
    "\n",
    "    originals = list(data.raw_sentence)\n",
    "    resolutions = list(data.full_resolution)\n",
    "    outputs = pipeline(originals)\n",
    "\n",
    "    predictions = []\n",
    "    for i, resolution in enumerate(resolutions):\n",
    "        generations = [entry['generated_text'] for entry in outputs[i]]\n",
    "        scores = [relative_edit_distance(gen, resolution, originals[i]) for gen in generations]\n",
    "        if debug and max(scores) == 1 and scores.index(max(scores)) != 0:\n",
    "            print(generations)\n",
    "            print(scores.index(max(scores)))\n",
    "            print(resolution)\n",
    "        predictions.append(generations[scores.index(max(scores))])\n",
    "\n",
    "    errors = error_analysis(predictions, resolutions, list(data.raw_sentence))\n",
    "\n",
    "    return errors, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "k = 5\n",
    "errors_k, outputs_k = evaluate_top_k(model, tokenizer, val_df, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_k.error_type.value_counts() / len(errors_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_k = pd.concat([errors_k, pd.Series(outputs_k, name='outputs_k')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_k.to_parquet(output_path / f'results_top{k}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "get_scores(results_k, SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ChatGPT/GPT to determine the best fit of the top k options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_multiple_choice_prompt(original, predictions):\n",
    "    # Das folgende Problem wurde von Yann LeCun gestellt, der sehr an der Kompetenz von Künstlicher Intelligenz, wie dir, zweifelt: \n",
    "    beginning = \"Dir werden im Folgenden ein Satz gezeigt, welcher sogennannte Koordinationsellipsen enthält. Das Ziel ist es diese zu aufzulösen. Ein Beispiel wäre 'Ibrutinib, ein Inhibitor der Bruton-Tyrosinkinase (BTK), ist in Deutschland als Erstlinien- und Rezidivtherapiee in der CLL zugelassen.' Die richtige Auflösung wäre 'Ibrutinib, ein Inhibitor der Bruton-Tyrosinkinase (BTK), ist in Deutschland als Erstlinientherapie und Rezidivtherapiee in der CLL zugelassen.' Dir werden zu den Beispielen Antwortmöglichkeiten gegeben und du sollst dann entscheiden, welche dieser Optionen die Koordinationsellipsen korrekt auflöst.\\n\\n\"\n",
    "    original = f\"Der originale Satz: '{original}'\\n\\n\"\n",
    "    answers = \"Deine Antwortmöglichkeiten:\\n\" + \"\".join(f\"{i+1}) '{prediction}'\\n\" for i, prediction in enumerate(predictions))\n",
    "    end = \"\\nWelche Antwort ist die richtige? Antworte nur mit der Zahl und keiner Erklärung\"\n",
    "\n",
    "    return beginning + original + answers + end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_prompt_true_false(original, predictions):\n",
    "    beginning = \"Sie haben ein Modell entwickelt, das Koordinationsellipsen in Sätzen erkennt und auflöst. Das Modell gibt fünf verschiedene Versionen des ursprünglichen Satzes zurück, wobei die erste Version die wahrscheinlichste ist. Bitte lesen Sie sich die erste Version des Satzes sorgfältig durch und entscheiden Sie, ob diese Version korrekt ist und den ursprünglichen Satz mit aufgelösten Koordinationsellipsen wiedergibt. Bitte antworten Sie mir nur 'Ja' oder 'Nein' und keiner Erklärung!\\n\\n\"\n",
    "    original = f\"Ursprünglicher Satz: '{original}'\\n\\n\"\n",
    "    answer = f\"Erste Version: '{predictions[0]}'\\n\\n\"\n",
    "\n",
    "    return beginning + original + answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_prompt_other_options(original, predictions):\n",
    "    beginning = \"Sie haben entschieden, dass die erste Version des Satzes, die vom Modell als die wahrscheinlichste ausgewählt wurde, nicht korrekt ist und den ursprünglichen Satz mit aufgelösten Koordinationsellipsen nicht vollständig wiedergibt. Das Modell gibt vier weitere Versionen des Satzes zurück, die als die nächst wahrscheinlichsten Versionen ausgewählt wurden. Bitte lesen Sie sich diese vier Versionen sorgfältig durch und wählen Sie die Version aus, die Ihrer Meinung nach am besten den ursprünglichen Satz mit aufgelösten Koordinationsellipsen wiedergibt.\\n\\n\"\n",
    "    answers = \"\" + \"\".join(f\"{i+1} - '{prediction}'\\n\" for i, prediction in enumerate(predictions[1:]))\n",
    "    end = \"\\nBitte antworten Sie nur mit der richtigen Nummer und ohne Erklärung.\"\n",
    "    return beginning + answers + end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best_fit_prompts(samples, outputs, ground_truths, prompt_fn):\n",
    "    prompt_df = []\n",
    "    for i, sample in enumerate(samples):\n",
    "        generations = [entry['generated_text'] for entry in outputs[i]]\n",
    "        ground_truth = ground_truths[i]\n",
    "        true_index = generations.index(ground_truth) if ground_truth in generations else -1\n",
    "        \n",
    "        prompt_df.append({\n",
    "            'input' : sample,\n",
    "            'generations' : generations,\n",
    "            'true_index' : true_index,\n",
    "            'prompt' : prompt_fn(sample, generations)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(prompt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retry import retry\n",
    "import logging\n",
    "logging.basicConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4-0125-preview\"\n",
    "#MODEL = \"gpt-3.5-turbo-1106\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "@retry(tries=3, delay=2)\n",
    "def get_openai_response_chatgpt(messages):\n",
    "    return openai.ChatCompletion.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": role, \"content\": text} for (role, text) in messages\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=100,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query GPT-3.5 to pick 1 from k options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_5 = pd.read_parquet(output_path / f'results_top5.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "def call_api_best_fit(prompt_df, skip_if_1st_unchanged=True, debug=False):\n",
    "    predictions = []\n",
    "\n",
    "    for i, row in tqdm(list(prompt_df.iterrows())):\n",
    "        generations = row.generations\n",
    "        sample = row.input\n",
    "        prompt = row.prompt\n",
    "        status = 'success'\n",
    "        \n",
    "        if skip_if_1st_unchanged and generations[0] == sample:\n",
    "            if debug:\n",
    "                print(f'{i}) answer: {0}')\n",
    "                print('--------------------------------')\n",
    "            predictions.append({'status': 'skipped', 'prediction' : generations[0], 'index' : 0, 'answer' : None})\n",
    "\n",
    "        else:\n",
    "            message = [(\"user\", prompt)]\n",
    "            answer = get_openai_response_chatgpt(message)\n",
    "\n",
    "            numbers = re.findall(r'\\d+', answer)\n",
    "            if len(numbers) > 1:\n",
    "                if debug:\n",
    "                    print(f'more numbers than expected {numbers}')\n",
    "                status = 'error_multiple'\n",
    "                index = numbers[0]\n",
    "            if len(numbers) == 0:\n",
    "                if debug:\n",
    "                    print(f'no numbers found')\n",
    "                index = 0\n",
    "                status = 'error_no_numbers'\n",
    "            else:\n",
    "                index = int(numbers[0]) - 1\n",
    "                if index >= len(generations):\n",
    "                    if debug:\n",
    "                        print(f'Index is out of bounds. Something went wrong with the API Answer. Defaulting to 0')\n",
    "                    index = 0\n",
    "                    status = 'error_out_of_bounds'\n",
    "\n",
    "            if debug:\n",
    "                print(f'{i}) answer: {index}')\n",
    "                print('--------------------------------')\n",
    "            predictions.append({'status' : status, 'prediction' : generations[index], 'index' : index, 'answer' : answer})\n",
    "    \n",
    "    return pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "originals_k = list(results_5.original)\n",
    "resolutions = list(results_5.ground_truth)\n",
    "outputs_k = list(results_5.outputs_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare prompts\n",
    "prompts_best_fit = generate_best_fit_prompts(originals_k, outputs_k, resolutions, generate_multiple_choice_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0ccc812ac74a4bab3f9dc3d9cc24f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.86 s, sys: 246 ms, total: 3.11 s\n",
      "Wall time: 9min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Call OpenAI API\n",
    "predictions = call_api_best_fit(prompts_best_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts2preds_bestfit = pd.concat([prompts_best_fit, predictions], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts2preds_bestfit.to_parquet(output_path / 'gpt_4_prompts2preds_bestfit.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "errors_best_fit = error_analysis(prompts2preds_bestfit.prediction, resolutions, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tn         597\n",
       "tp         434\n",
       "replace     33\n",
       "insert      26\n",
       "delete      26\n",
       "fn          23\n",
       "complex     11\n",
       "fp           9\n",
       "Name: error_type, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_best_fit.error_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 47.5 ms, total: 1min 23s\n",
      "Wall time: 1min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test/exact_match': 0.8895599654874892,\n",
       " 'test/gleu': 0.9804849105524535,\n",
       " 'test/edit_distance_rel': 0.9518765393803748}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_scores(errors_best_fit, SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Step Approach: 1. Ask if 1st option is correct 2. choose from options 2-k otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>original</th>\n",
       "      <th>error_type</th>\n",
       "      <th>index</th>\n",
       "      <th>file</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>outputs_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hauptrisikofaktoren für das Auftreten eines Mu...</td>\n",
       "      <td>Hauptrisikofaktoren für das Auftreten eines Mu...</td>\n",
       "      <td>Hauptrisikofaktoren für das Auftreten eines Mu...</td>\n",
       "      <td>tp</td>\n",
       "      <td>0</td>\n",
       "      <td>00_mundhoehlenkarzinom_0002.tsv</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'generated_text': 'Hauptrisikofaktoren für d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bei chronischem Tabakabusus oder Alkoholabusus...</td>\n",
       "      <td>Bei chronischem Tabakabusus oder Alkoholabusus...</td>\n",
       "      <td>Bei chronischem Tabak- oder Alkoholabusus ist ...</td>\n",
       "      <td>tp</td>\n",
       "      <td>1</td>\n",
       "      <td>00_mundhoehlenkarzinom_0002.tsv</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'generated_text': 'Bei chronischem Tabakabus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Als kurativ intendierte therapeutische Optione...</td>\n",
       "      <td>Als kurativ intendierte therapeutische Optione...</td>\n",
       "      <td>Als kurativ intendierte therapeutische Optione...</td>\n",
       "      <td>tp</td>\n",
       "      <td>40</td>\n",
       "      <td>00_mundhoehlenkarzinom_0098.tsv</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'generated_text': 'Als kurativ intendierte t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patienten mit einem unheilbaren Tumorleiden, j...</td>\n",
       "      <td>Patienten mit einem unheilbaren Tumorleiden, j...</td>\n",
       "      <td>Patienten mit einem unheilbaren Tumorleiden, j...</td>\n",
       "      <td>tp</td>\n",
       "      <td>44</td>\n",
       "      <td>00_mundhoehlenkarzinom_0103.tsv</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'generated_text': 'Patienten mit einem unhei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patienten mit einem unheilbaren Tumorleiden, j...</td>\n",
       "      <td>Patienten mit einem unheilbaren Tumorleiden, j...</td>\n",
       "      <td>Patienten mit einem unheilbaren Tumorleiden, j...</td>\n",
       "      <td>tp</td>\n",
       "      <td>47</td>\n",
       "      <td>00_mundhoehlenkarzinom_0115.tsv</td>\n",
       "      <td>4</td>\n",
       "      <td>[{'generated_text': 'Patienten mit einem unhei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                pred  \\\n",
       "0  Hauptrisikofaktoren für das Auftreten eines Mu...   \n",
       "1  Bei chronischem Tabakabusus oder Alkoholabusus...   \n",
       "2  Als kurativ intendierte therapeutische Optione...   \n",
       "3  Patienten mit einem unheilbaren Tumorleiden, j...   \n",
       "4  Patienten mit einem unheilbaren Tumorleiden, j...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  Hauptrisikofaktoren für das Auftreten eines Mu...   \n",
       "1  Bei chronischem Tabakabusus oder Alkoholabusus...   \n",
       "2  Als kurativ intendierte therapeutische Optione...   \n",
       "3  Patienten mit einem unheilbaren Tumorleiden, j...   \n",
       "4  Patienten mit einem unheilbaren Tumorleiden, j...   \n",
       "\n",
       "                                            original error_type  index  \\\n",
       "0  Hauptrisikofaktoren für das Auftreten eines Mu...         tp      0   \n",
       "1  Bei chronischem Tabak- oder Alkoholabusus ist ...         tp      1   \n",
       "2  Als kurativ intendierte therapeutische Optione...         tp     40   \n",
       "3  Patienten mit einem unheilbaren Tumorleiden, j...         tp     44   \n",
       "4  Patienten mit einem unheilbaren Tumorleiden, j...         tp     47   \n",
       "\n",
       "                              file  sentence_id  \\\n",
       "0  00_mundhoehlenkarzinom_0002.tsv            1   \n",
       "1  00_mundhoehlenkarzinom_0002.tsv            2   \n",
       "2  00_mundhoehlenkarzinom_0098.tsv            2   \n",
       "3  00_mundhoehlenkarzinom_0103.tsv            1   \n",
       "4  00_mundhoehlenkarzinom_0115.tsv            4   \n",
       "\n",
       "                                           outputs_k  \n",
       "0  [{'generated_text': 'Hauptrisikofaktoren für d...  \n",
       "1  [{'generated_text': 'Bei chronischem Tabakabus...  \n",
       "2  [{'generated_text': 'Als kurativ intendierte t...  \n",
       "3  [{'generated_text': 'Patienten mit einem unhei...  \n",
       "4  [{'generated_text': 'Patienten mit einem unhei...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_5 = pd.read_parquet(output_path / 'results_top5.parquet')\n",
    "results_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sie haben ein Modell entwickelt, das Koordinationsellipsen in Sätzen erkennt und auflöst. Das Modell gibt fünf verschiedene Versionen des ursprünglichen Satzes zurück, wobei die erste Version die wahrscheinlichste ist. Bitte lesen Sie sich die erste Version des Satzes sorgfältig durch und entscheiden Sie, ob diese Version korrekt ist und den ursprünglichen Satz mit aufgelösten Koordinationsellipsen wiedergibt. Bitte antworten Sie mir nur 'Ja' oder 'Nein' und keiner Erklärung!\n",
      "\n",
      "Ursprünglicher Satz: 'Hauptrisikofaktoren für das Auftreten eines Mundhöhlenkarzinoms sind chronischer Tabak- oder Alkoholabusus, wesentlich seltener auch andere Faktoren.'\n",
      "\n",
      "Erste Version: 'Hauptrisikofaktoren für das Auftreten eines Mundhöhlenkarzinoms sind chronischer Tabakabusus oder Alkoholabusus, wesentlich seltener auch andere Faktoren.'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top1_classifier_prompts = generate_best_fit_prompts(results_5.original, results_5.outputs_k, results_5.ground_truth, generate_prompt_true_false)\n",
    "print(top1_classifier_prompts.iloc[0].prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "def call_api_top1_classifier(prompt_df, skip_if_1st_unchanged=True, debug=False):\n",
    "    predictions = []\n",
    "    for i, row in tqdm(list(prompt_df.iterrows())):\n",
    "        sample = row.input\n",
    "        generations = row.generations\n",
    "        prompt = row.prompt\n",
    "\n",
    "        if skip_if_1st_unchanged and generations[0] == sample:\n",
    "            if debug:\n",
    "                print(f'{i}) answer: {0}')\n",
    "                print('--------------------------------')\n",
    "            predictions.append({'status': 'skipped', 'prediction1' : generations[0], 'accept' : True, 'answer' : None})\n",
    "        else:\n",
    "            message = [(\"user\", prompt)]\n",
    "            answer = get_openai_response_chatgpt(message)\n",
    "            extracted_answer = re.findall(r'Ja|Nein', answer)\n",
    "            if len(extracted_answer) > 1:\n",
    "                if debug:\n",
    "                    print(f'more answers than expected: {answer}. Defaulting to 0')\n",
    "                    print(f'{i}) answer: {0}')\n",
    "                    print('--------------------------------')\n",
    "                predictions.append({'status': 'error_multiple', 'prediction1' : generations[0], 'accept' : True, 'answer' : answer})\n",
    "            elif len(extracted_answer) == 0:\n",
    "                if debug:\n",
    "                    print(f'No answer provided: {answer}. Defaulting to 0')\n",
    "                    print(f'{i}) answer: {0}')\n",
    "                    print('--------------------------------')\n",
    "                predictions.append({'status': 'error_no_answer', 'prediction1' : generations[0], 'accept' : True, 'answer' : answer})\n",
    "            elif extracted_answer[0] == 'Ja':\n",
    "                if debug:\n",
    "                    print(f'{i}) answer: {0}')\n",
    "                    print('--------------------------------')\n",
    "                predictions.append({'status': 'success', 'prediction1' : generations[0], 'accept' : True, 'answer' : answer})\n",
    "            elif extracted_answer[0] == 'Nein':\n",
    "                if debug:\n",
    "                    print(f'{i}) answer: != 0')\n",
    "                    print('--------------------------------')\n",
    "                predictions.append({'status': 'success', 'prediction1' : None, 'accept' : False, 'answer' : answer})\n",
    "    return pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b76ad6a5432432c86ad86df2bcbb648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_1 = call_api_top1_classifier(top1_classifier_prompts, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2predictions_1 = pd.concat([top1_classifier_prompts, predictions_1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2predictions_1.to_parquet(output_path / 'prompt2predictions_1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1108\n",
       "False      51\n",
       "Name: accept, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt2predictions_1.accept.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033393501805054154"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted = prompt2predictions_1[prompt2predictions_1.accept]\n",
    "len(accepted[accepted.true_index > 0]) / len(accepted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27450980392156865"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_accepted = prompt2predictions_1[~prompt2predictions_1.accept]\n",
    "len(not_accepted[not_accepted.true_index > 0]) / len(not_accepted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask GPT to choose from remaining options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>original</th>\n",
       "      <th>error_type</th>\n",
       "      <th>index</th>\n",
       "      <th>file</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>outputs_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hauptrisikofaktoren für das Auftreten eines Mu...</td>\n",
       "      <td>Hauptrisikofaktoren für das Auftreten eines Mu...</td>\n",
       "      <td>Hauptrisikofaktoren für das Auftreten eines Mu...</td>\n",
       "      <td>tp</td>\n",
       "      <td>0</td>\n",
       "      <td>00_mundhoehlenkarzinom_0002.tsv</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'generated_text': 'Hauptrisikofaktoren für d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bei chronischem Tabakabusus oder Alkoholabusus...</td>\n",
       "      <td>Bei chronischem Tabakabusus oder Alkoholabusus...</td>\n",
       "      <td>Bei chronischem Tabak- oder Alkoholabusus ist ...</td>\n",
       "      <td>tp</td>\n",
       "      <td>1</td>\n",
       "      <td>00_mundhoehlenkarzinom_0002.tsv</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'generated_text': 'Bei chronischem Tabakabus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Als kurativ intendierte therapeutische Optione...</td>\n",
       "      <td>Als kurativ intendierte therapeutische Optione...</td>\n",
       "      <td>Als kurativ intendierte therapeutische Optione...</td>\n",
       "      <td>tp</td>\n",
       "      <td>40</td>\n",
       "      <td>00_mundhoehlenkarzinom_0098.tsv</td>\n",
       "      <td>2</td>\n",
       "      <td>[{'generated_text': 'Als kurativ intendierte t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patienten mit einem unheilbaren Tumorleiden, j...</td>\n",
       "      <td>Patienten mit einem unheilbaren Tumorleiden, j...</td>\n",
       "      <td>Patienten mit einem unheilbaren Tumorleiden, j...</td>\n",
       "      <td>tp</td>\n",
       "      <td>44</td>\n",
       "      <td>00_mundhoehlenkarzinom_0103.tsv</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'generated_text': 'Patienten mit einem unhei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patienten mit einem unheilbaren Tumorleiden, j...</td>\n",
       "      <td>Patienten mit einem unheilbaren Tumorleiden, j...</td>\n",
       "      <td>Patienten mit einem unheilbaren Tumorleiden, j...</td>\n",
       "      <td>tp</td>\n",
       "      <td>47</td>\n",
       "      <td>00_mundhoehlenkarzinom_0115.tsv</td>\n",
       "      <td>4</td>\n",
       "      <td>[{'generated_text': 'Patienten mit einem unhei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                pred  \\\n",
       "0  Hauptrisikofaktoren für das Auftreten eines Mu...   \n",
       "1  Bei chronischem Tabakabusus oder Alkoholabusus...   \n",
       "2  Als kurativ intendierte therapeutische Optione...   \n",
       "3  Patienten mit einem unheilbaren Tumorleiden, j...   \n",
       "4  Patienten mit einem unheilbaren Tumorleiden, j...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  Hauptrisikofaktoren für das Auftreten eines Mu...   \n",
       "1  Bei chronischem Tabakabusus oder Alkoholabusus...   \n",
       "2  Als kurativ intendierte therapeutische Optione...   \n",
       "3  Patienten mit einem unheilbaren Tumorleiden, j...   \n",
       "4  Patienten mit einem unheilbaren Tumorleiden, j...   \n",
       "\n",
       "                                            original error_type  index  \\\n",
       "0  Hauptrisikofaktoren für das Auftreten eines Mu...         tp      0   \n",
       "1  Bei chronischem Tabak- oder Alkoholabusus ist ...         tp      1   \n",
       "2  Als kurativ intendierte therapeutische Optione...         tp     40   \n",
       "3  Patienten mit einem unheilbaren Tumorleiden, j...         tp     44   \n",
       "4  Patienten mit einem unheilbaren Tumorleiden, j...         tp     47   \n",
       "\n",
       "                              file  sentence_id  \\\n",
       "0  00_mundhoehlenkarzinom_0002.tsv            1   \n",
       "1  00_mundhoehlenkarzinom_0002.tsv            2   \n",
       "2  00_mundhoehlenkarzinom_0098.tsv            2   \n",
       "3  00_mundhoehlenkarzinom_0103.tsv            1   \n",
       "4  00_mundhoehlenkarzinom_0115.tsv            4   \n",
       "\n",
       "                                           outputs_k  \n",
       "0  [{'generated_text': 'Hauptrisikofaktoren für d...  \n",
       "1  [{'generated_text': 'Bei chronischem Tabakabus...  \n",
       "2  [{'generated_text': 'Als kurativ intendierte t...  \n",
       "3  [{'generated_text': 'Patienten mit einem unhei...  \n",
       "4  [{'generated_text': 'Patienten mit einem unhei...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_5 = pd.read_parquet(output_path / 'results_top5.parquet')\n",
    "results_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>generations</th>\n",
       "      <th>true_index</th>\n",
       "      <th>prompt</th>\n",
       "      <th>status</th>\n",
       "      <th>prediction1</th>\n",
       "      <th>accept</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hauptrisikofaktoren für das Auftreten eines Mu...</td>\n",
       "      <td>[Hauptrisikofaktoren für das Auftreten eines M...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sie haben ein Modell entwickelt, das Koordinat...</td>\n",
       "      <td>success</td>\n",
       "      <td>Hauptrisikofaktoren für das Auftreten eines Mu...</td>\n",
       "      <td>True</td>\n",
       "      <td>Ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bei chronischem Tabak- oder Alkoholabusus ist ...</td>\n",
       "      <td>[Bei chronischem Tabakabusus oder Alkoholabusu...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sie haben ein Modell entwickelt, das Koordinat...</td>\n",
       "      <td>success</td>\n",
       "      <td>Bei chronischem Tabakabusus oder Alkoholabusus...</td>\n",
       "      <td>True</td>\n",
       "      <td>Ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Als kurativ intendierte therapeutische Optione...</td>\n",
       "      <td>[Als kurativ intendierte therapeutische Option...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sie haben ein Modell entwickelt, das Koordinat...</td>\n",
       "      <td>success</td>\n",
       "      <td>Als kurativ intendierte therapeutische Optione...</td>\n",
       "      <td>True</td>\n",
       "      <td>Ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patienten mit einem unheilbaren Tumorleiden, j...</td>\n",
       "      <td>[Patienten mit einem unheilbaren Tumorleiden, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sie haben ein Modell entwickelt, das Koordinat...</td>\n",
       "      <td>success</td>\n",
       "      <td>Patienten mit einem unheilbaren Tumorleiden, j...</td>\n",
       "      <td>True</td>\n",
       "      <td>Ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patienten mit einem unheilbaren Tumorleiden, j...</td>\n",
       "      <td>[Patienten mit einem unheilbaren Tumorleiden, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sie haben ein Modell entwickelt, das Koordinat...</td>\n",
       "      <td>success</td>\n",
       "      <td>Patienten mit einem unheilbaren Tumorleiden, j...</td>\n",
       "      <td>True</td>\n",
       "      <td>Ja</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  Hauptrisikofaktoren für das Auftreten eines Mu...   \n",
       "1  Bei chronischem Tabak- oder Alkoholabusus ist ...   \n",
       "2  Als kurativ intendierte therapeutische Optione...   \n",
       "3  Patienten mit einem unheilbaren Tumorleiden, j...   \n",
       "4  Patienten mit einem unheilbaren Tumorleiden, j...   \n",
       "\n",
       "                                         generations  true_index  \\\n",
       "0  [Hauptrisikofaktoren für das Auftreten eines M...           0   \n",
       "1  [Bei chronischem Tabakabusus oder Alkoholabusu...           0   \n",
       "2  [Als kurativ intendierte therapeutische Option...           0   \n",
       "3  [Patienten mit einem unheilbaren Tumorleiden, ...           0   \n",
       "4  [Patienten mit einem unheilbaren Tumorleiden, ...           0   \n",
       "\n",
       "                                              prompt   status  \\\n",
       "0  Sie haben ein Modell entwickelt, das Koordinat...  success   \n",
       "1  Sie haben ein Modell entwickelt, das Koordinat...  success   \n",
       "2  Sie haben ein Modell entwickelt, das Koordinat...  success   \n",
       "3  Sie haben ein Modell entwickelt, das Koordinat...  success   \n",
       "4  Sie haben ein Modell entwickelt, das Koordinat...  success   \n",
       "\n",
       "                                         prediction1  accept answer  \n",
       "0  Hauptrisikofaktoren für das Auftreten eines Mu...    True     Ja  \n",
       "1  Bei chronischem Tabakabusus oder Alkoholabusus...    True     Ja  \n",
       "2  Als kurativ intendierte therapeutische Optione...    True     Ja  \n",
       "3  Patienten mit einem unheilbaren Tumorleiden, j...    True     Ja  \n",
       "4  Patienten mit einem unheilbaren Tumorleiden, j...    True     Ja  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt2predictions_1 = pd.read_parquet(output_path / 'prompt2predictions_1.parquet')\n",
    "prompt2predictions_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sie haben entschieden, dass die erste Version des Satzes, die vom Modell als die wahrscheinlichste ausgewählt wurde, nicht korrekt ist und den ursprünglichen Satz mit aufgelösten Koordinationsellipsen nicht vollständig wiedergibt. Das Modell gibt vier weitere Versionen des Satzes zurück, die als die nächst wahrscheinlichsten Versionen ausgewählt wurden. Bitte lesen Sie sich diese vier Versionen sorgfältig durch und wählen Sie die Version aus, die Ihrer Meinung nach am besten den ursprünglichen Satz mit aufgelösten Koordinationsellipsen wiedergibt.\n",
      "\n",
      "1 - 'Nebenrisikofaktoren für das Auftreten eines Mundhöhlenkarzinoms sind chronischer Tabakabusus oder Alkoholabusus, wesentlich seltener auch andere Faktoren.'\n",
      "2 - 'Hauptrisikofaktoren für das Auftreten eines Mundhöhlenkarzinoms sind chronischer Tabakabusus oder Alkoholabusus, wesentlich seltener und andere Faktoren.'\n",
      "3 - 'Kopfrisikofaktoren für das Auftreten eines Mundhöhlenkarzinoms sind chronischer Tabakabusus oder Alkoholabusus, wesentlich seltener auch andere Faktoren.'\n",
      "4 - 'Hauptrisikofaktoren für das Auftreten eines Mundhöhlenkarzinoms sind chronischer Tabakobusus oder Alkoholabusus, wesentlich seltener auch andere Faktoren.'\n",
      "\n",
      "Bitte antworten Sie nur mit der richtigen Nummer und ohne Erklärung.\n"
     ]
    }
   ],
   "source": [
    "other_options_prompts = generate_best_fit_prompts(results_5.original, results_5.outputs_k, results_5.ground_truth, generate_prompt_other_options)\n",
    "print(other_options_prompts.iloc[0].prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>generations</th>\n",
       "      <th>true_index</th>\n",
       "      <th>prompt</th>\n",
       "      <th>status</th>\n",
       "      <th>prediction1</th>\n",
       "      <th>accept</th>\n",
       "      <th>answer</th>\n",
       "      <th>prompt2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hauptrisikofaktoren für das Auftreten eines Mu...</td>\n",
       "      <td>[Hauptrisikofaktoren für das Auftreten eines M...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sie haben ein Modell entwickelt, das Koordinat...</td>\n",
       "      <td>success</td>\n",
       "      <td>Hauptrisikofaktoren für das Auftreten eines Mu...</td>\n",
       "      <td>True</td>\n",
       "      <td>Ja</td>\n",
       "      <td>Sie haben entschieden, dass die erste Version ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bei chronischem Tabak- oder Alkoholabusus ist ...</td>\n",
       "      <td>[Bei chronischem Tabakabusus oder Alkoholabusu...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sie haben ein Modell entwickelt, das Koordinat...</td>\n",
       "      <td>success</td>\n",
       "      <td>Bei chronischem Tabakabusus oder Alkoholabusus...</td>\n",
       "      <td>True</td>\n",
       "      <td>Ja</td>\n",
       "      <td>Sie haben entschieden, dass die erste Version ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Als kurativ intendierte therapeutische Optione...</td>\n",
       "      <td>[Als kurativ intendierte therapeutische Option...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sie haben ein Modell entwickelt, das Koordinat...</td>\n",
       "      <td>success</td>\n",
       "      <td>Als kurativ intendierte therapeutische Optione...</td>\n",
       "      <td>True</td>\n",
       "      <td>Ja</td>\n",
       "      <td>Sie haben entschieden, dass die erste Version ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patienten mit einem unheilbaren Tumorleiden, j...</td>\n",
       "      <td>[Patienten mit einem unheilbaren Tumorleiden, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sie haben ein Modell entwickelt, das Koordinat...</td>\n",
       "      <td>success</td>\n",
       "      <td>Patienten mit einem unheilbaren Tumorleiden, j...</td>\n",
       "      <td>True</td>\n",
       "      <td>Ja</td>\n",
       "      <td>Sie haben entschieden, dass die erste Version ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patienten mit einem unheilbaren Tumorleiden, j...</td>\n",
       "      <td>[Patienten mit einem unheilbaren Tumorleiden, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sie haben ein Modell entwickelt, das Koordinat...</td>\n",
       "      <td>success</td>\n",
       "      <td>Patienten mit einem unheilbaren Tumorleiden, j...</td>\n",
       "      <td>True</td>\n",
       "      <td>Ja</td>\n",
       "      <td>Sie haben entschieden, dass die erste Version ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  Hauptrisikofaktoren für das Auftreten eines Mu...   \n",
       "1  Bei chronischem Tabak- oder Alkoholabusus ist ...   \n",
       "2  Als kurativ intendierte therapeutische Optione...   \n",
       "3  Patienten mit einem unheilbaren Tumorleiden, j...   \n",
       "4  Patienten mit einem unheilbaren Tumorleiden, j...   \n",
       "\n",
       "                                         generations  true_index  \\\n",
       "0  [Hauptrisikofaktoren für das Auftreten eines M...           0   \n",
       "1  [Bei chronischem Tabakabusus oder Alkoholabusu...           0   \n",
       "2  [Als kurativ intendierte therapeutische Option...           0   \n",
       "3  [Patienten mit einem unheilbaren Tumorleiden, ...           0   \n",
       "4  [Patienten mit einem unheilbaren Tumorleiden, ...           0   \n",
       "\n",
       "                                              prompt   status  \\\n",
       "0  Sie haben ein Modell entwickelt, das Koordinat...  success   \n",
       "1  Sie haben ein Modell entwickelt, das Koordinat...  success   \n",
       "2  Sie haben ein Modell entwickelt, das Koordinat...  success   \n",
       "3  Sie haben ein Modell entwickelt, das Koordinat...  success   \n",
       "4  Sie haben ein Modell entwickelt, das Koordinat...  success   \n",
       "\n",
       "                                         prediction1  accept answer  \\\n",
       "0  Hauptrisikofaktoren für das Auftreten eines Mu...    True     Ja   \n",
       "1  Bei chronischem Tabakabusus oder Alkoholabusus...    True     Ja   \n",
       "2  Als kurativ intendierte therapeutische Optione...    True     Ja   \n",
       "3  Patienten mit einem unheilbaren Tumorleiden, j...    True     Ja   \n",
       "4  Patienten mit einem unheilbaren Tumorleiden, j...    True     Ja   \n",
       "\n",
       "                                             prompt2  \n",
       "0  Sie haben entschieden, dass die erste Version ...  \n",
       "1  Sie haben entschieden, dass die erste Version ...  \n",
       "2  Sie haben entschieden, dass die erste Version ...  \n",
       "3  Sie haben entschieden, dass die erste Version ...  \n",
       "4  Sie haben entschieden, dass die erste Version ...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt2predictions_2 = pd.concat([prompt2predictions_1, other_options_prompts.prompt.rename('prompt2')], axis=1)\n",
    "prompt2predictions_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sie haben entschieden, dass die erste Version des Satzes, die vom Modell als die wahrscheinlichste ausgewählt wurde, nicht korrekt ist und den ursprünglichen Satz mit aufgelösten Koordinationsellipsen nicht vollständig wiedergibt. Das Modell gibt vier weitere Versionen des Satzes zurück, die als die nächst wahrscheinlichsten Versionen ausgewählt wurden. Bitte lesen Sie sich diese vier Versionen sorgfältig durch und wählen Sie die Version aus, die Ihrer Meinung nach am besten den ursprünglichen Satz mit aufgelösten Koordinationsellipsen wiedergibt.\\n\\n1 - 'Nebenrisikofaktoren für das Auftreten eines Mundhöhlenkarzinoms sind chronischer Tabakabusus oder Alkoholabusus, wesentlich seltener auch andere Faktoren.'\\n2 - 'Hauptrisikofaktoren für das Auftreten eines Mundhöhlenkarzinoms sind chronischer Tabakabusus oder Alkoholabusus, wesentlich seltener und andere Faktoren.'\\n3 - 'Kopfrisikofaktoren für das Auftreten eines Mundhöhlenkarzinoms sind chronischer Tabakabusus oder Alkoholabusus, wesentlich seltener auch andere Faktoren.'\\n4 - 'Hauptrisikofaktoren für das Auftreten eines Mundhöhlenkarzinoms sind chronischer Tabakobusus oder Alkoholabusus, wesentlich seltener auch andere Faktoren.'\\n\\nBitte antworten Sie nur mit der richtigen Nummer und ohne Erklärung.\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt2predictions_2.head().prompt2.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_api_otheroptions_classifier(prompt_df, debug=False):\n",
    "    predictions = []\n",
    "    for i, row in tqdm(list(prompt_df.iterrows())):\n",
    "        if row.accept:\n",
    "            if debug:\n",
    "                print(f'{i} was accepted previously.')\n",
    "            predictions.append({'status2': 'accept_1', 'prediction2' : row.prediction1, 'answer2' : None})\n",
    "        else:\n",
    "            prompt1 = row.prompt\n",
    "            answer = row.answer\n",
    "            prompt2 = row.prompt2\n",
    "\n",
    "            messages = [(\"user\", prompt1), (\"assistant\", answer), (\"user\", prompt2)]\n",
    "\n",
    "            answer2 = get_openai_response_chatgpt(messages)\n",
    "\n",
    "            numbers = re.findall(r'\\d+', answer2)\n",
    "            if len(numbers) > 1:\n",
    "                if debug:\n",
    "                    print(f'more numbers than expected {numbers}')\n",
    "                predictions.append({'status2': 'error_multiple', 'prediction2' : row.generations[1], 'answer2' : answer2})\n",
    "            if len(numbers) == 0:\n",
    "                if debug:\n",
    "                    print(f'no numbers found')\n",
    "                predictions.append({'status2': 'no_numbers', 'prediction2' : row.generations[1], 'answer2' : answer2})\n",
    "            else:\n",
    "                index = int(numbers[0])\n",
    "                if index > 4:\n",
    "                    if debug:\n",
    "                        print(f'Index is out of bounds. Something went wrong with the API Answer. Defaulting to 0')\n",
    "                    predictions.append({'status2': 'no_numbers', 'prediction2' : row.generations[1], 'answer2' : answer2})\n",
    "                else:\n",
    "                    predictions.append({'status2': 'success', 'prediction2' : row.generations[index], 'answer2' : answer2})\n",
    "    return pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e5087e7b7d46f1874351373fc32dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1159 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_2 = call_api_otheroptions_classifier(prompt2predictions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = pd.concat([prompt2predictions_2, predictions_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_2 = error_analysis(result2.prediction2, df.full_resolution, result2.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tn         596\n",
       "tp         429\n",
       "delete      31\n",
       "fn          30\n",
       "insert      24\n",
       "replace     22\n",
       "complex     17\n",
       "fp          10\n",
       "Name: error_type, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_2.error_type.value_counts()# / len(errors_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 17 ms, total: 1min 17s\n",
      "Wall time: 1min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test/exact_match': 0.8843830888697153,\n",
       " 'test/gleu': 0.9796026253080345,\n",
       " 'test/edit_distance_rel': 0.9432361574177688}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_scores(errors_2, SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline TOP 1 only\n",
    "errors_top1 = pd.read_parquet(output_path / 'results_top1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_top1.error_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "get_scores(errors_top1, SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_temp = error_analysis(result2.generations.map(lambda l: l[0]), val_df.full_resolution, result2.input)\n",
    "errors_temp.error_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ellipses]",
   "language": "python",
   "name": "conda-env-ellipses-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
